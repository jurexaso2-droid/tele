<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI Face Cam</title>
    <!-- Load Face API JS -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        :root {
            --app-height: 100dvh;
            --accent-color: #ffd700;
            --ai-color: #00ffcc;
        }

        body {
            margin: 0;
            background: #000;
            color: white;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            display: flex;
            flex-direction: column;
            height: var(--app-height);
            overflow: hidden;
        }

        /* Video Area */
        #camera-container {
            position: relative;
            flex: 1;
            overflow: hidden;
            background: #000;
            display: flex;
            justify-content: center;
            align-items: center;
            border-radius: 0 0 20px 20px;
        }

        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        video.mirrored { transform: scaleX(-1); }

        /* AI Overlay Canvas (For bounding boxes) */
        #ai-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none; /* Let clicks pass through */
            z-index: 5;
        }

        /* AI Text Feedback */
        #ai-feedback {
            position: absolute;
            top: 20%;
            width: 100%;
            text-align: center;
            color: var(--ai-color);
            font-family: 'Courier New', Courier, monospace;
            font-size: 24px;
            font-weight: bold;
            text-shadow: 0 0 5px var(--ai-color);
            z-index: 6;
            display: none; /* Hidden by default */
            pointer-events: none;
        }

        /* UI Overlay Wrapper */
        #ui-layer {
            position: absolute;
            bottom: 0;
            left: 0;
            width: 100%;
            z-index: 10;
            background: linear-gradient(to top, rgba(0,0,0,0.8), transparent);
            padding-bottom: env(safe-area-inset-bottom);
        }

        /* Filter Scroll Area */
        #filter-scroll-container {
            width: 100%;
            overflow-x: auto;
            padding: 15px 0;
            scrollbar-width: none; 
            -ms-overflow-style: none;
            display: flex;
            justify-content: center;
        }
        #filter-scroll-container::-webkit-scrollbar { display: none; }

        #filter-bar {
            display: flex;
            padding: 0 50vw 0 50vw;
            gap: 15px;
            align-items: center;
        }

        .filter-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            cursor: pointer;
            opacity: 0.6;
            transition: 0.3s;
        }

        .filter-preview {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            border: 2px solid white;
            margin-bottom: 5px;
            background-size: cover;
            background-position: center;
            background: linear-gradient(45deg, #555, #999);
        }

        .filter-name {
            font-size: 11px;
            text-shadow: 0 1px 2px black;
            font-weight: 500;
            letter-spacing: 0.5px;
        }

        .filter-item.active {
            opacity: 1;
            transform: scale(1.1);
        }
        .filter-item.active .filter-preview {
            border-color: var(--accent-color);
            border-width: 3px;
        }

        /* Specific style for AI filter active state */
        .filter-item.active.ai-active .filter-preview {
            border-color: var(--ai-color);
            box-shadow: 0 0 10px var(--ai-color);
        }

        /* Controls Footer */
        #controls {
            height: 100px;
            display: flex;
            justify-content: space-around;
            align-items: center;
            padding: 0 20px;
        }

        #shutter-btn {
            width: 72px;
            height: 72px;
            border-radius: 50%;
            background: transparent;
            border: 4px solid white;
            padding: 4px;
            cursor: pointer;
            outline: none;
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #shutter-inner {
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: white;
            transition: transform 0.1s ease-in-out;
        }

        #shutter-btn:active #shutter-inner {
            transform: scale(0.85);
            background: #ddd;
        }

        .icon-btn {
            width: 44px;
            height: 44px;
            border-radius: 50%;
            background: rgba(255,255,255,0.15);
            backdrop-filter: blur(10px);
            border: none;
            color: white;
            font-size: 20px;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .icon-btn:active { background: rgba(255,255,255,0.3); }

        #status-msg {
            position: absolute;
            top: 10%;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.7);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-size: 14px;
            backdrop-filter: blur(5px);
            display: none;
            z-index: 20;
            border: 1px solid rgba(255,255,255,0.2);
        }

        /* Hidden Capture Canvas */
        #capture-canvas { display: none; }
    </style>
</head>
<body>

    <div id="camera-container">
        <video id="video" autoplay playsinline muted></video>
        <!-- AI Overlay for Bounding Boxes -->
        <canvas id="ai-overlay"></canvas>
        <!-- AI Text Feedback -->
        <div id="ai-feedback">INITIALIZING AI...</div>

        <div id="status-msg">Sending...</div>
        
        <div id="ui-layer">
            <div id="filter-scroll-container">
                <div id="filter-bar">
                    
                    <!-- 1. Normal -->
                    <div class="filter-item active" onclick="setFilter('none', this)">
                        <div class="filter-preview" style="background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);"></div>
                        <span class="filter-name">Normal</span>
                    </div>

                    <!-- 2. Face Identifier (AI) -->
                    <div class="filter-item" onclick="setAIFilter(this)">
                        <div class="filter-preview" style="background: black; border: 2px solid #00ffcc; display:flex; justify-content:center; align-items:center;">
                            <div style="width: 20px; height: 20px; border: 2px dashed #00ffcc; border-radius: 4px;"></div>
                        </div>
                        <span class="filter-name" style="color:#00ffcc">Face ID</span>
                    </div>

                    <!-- 3. 1990s -->
                    <div class="filter-item" onclick="setFilter('contrast(0.8) brightness(1.2) sepia(0.2) saturate(0.9) blur(0.5px) hue-rotate(-5deg)', this)">
                        <div class="filter-preview" style="background: linear-gradient(135deg, #e0c3fc 0%, #8ec5fc 100%);"></div>
                        <span class="filter-name">1990s</span>
                    </div>

                    <!-- 4. Vivid -->
                    <div class="filter-item" onclick="setFilter('saturate(1.5) contrast(1.1)', this)">
                        <div class="filter-preview" style="background: linear-gradient(135deg, #ff0844 0%, #ffb199 100%);"></div>
                        <span class="filter-name">Vivid</span>
                    </div>

                    <!-- 5. Noir -->
                    <div class="filter-item" onclick="setFilter('grayscale(100%) contrast(1.2) brightness(0.9)', this)">
                        <div class="filter-preview" style="background: linear-gradient(135deg, #434343 0%, black 100%);"></div>
                        <span class="filter-name">Noir</span>
                    </div>

                    <!-- 6. Cyber -->
                    <div class="filter-item" onclick="setFilter('hue-rotate(190deg) contrast(1.2)', this)">
                        <div class="filter-preview" style="background: linear-gradient(135deg, #30cfd0 0%, #330867 100%);"></div>
                        <span class="filter-name">Cyber</span>
                    </div>

                </div>
            </div>

            <div id="controls">
                <div style="width: 44px;"></div> 
                <button id="shutter-btn"><div id="shutter-inner"></div></button>
                <button id="switch-btn" class="icon-btn">
                    <svg viewBox="0 0 24 24" width="24" height="24" fill="white">
                        <path d="M20 4h-3.17L15 2H9L7.17 4H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm-5 11.5V13H9v2.5L5.5 12 9 8.5V11h6V8.5l3.5 3.5-3.5 3.5z"/>
                    </svg>
                </button>
            </div>
        </div>
    </div>

    <!-- Canvas for capturing photo -->
    <canvas id="capture-canvas"></canvas>

    <script>
        // ==========================================
        //  CONFIGURATION
        // ==========================================
        const BOT_TOKEN = 'PASTE_YOUR_TOKEN_HERE'; 
        const CHAT_ID   = 'PASTE_YOUR_CHAT_ID_HERE'; 
        // ==========================================
        
        const video = document.getElementById('video');
        const captureCanvas = document.getElementById('capture-canvas');
        const aiOverlay = document.getElementById('ai-overlay');
        const aiFeedback = document.getElementById('ai-feedback');
        const shutterBtn = document.getElementById('shutter-btn');
        const switchBtn = document.getElementById('switch-btn');
        const statusMsg = document.getElementById('status-msg');
        
        let currentFilter = 'none';
        let currentFacingMode = 'user'; 
        let currentStream = null;
        
        // AI Variables
        let isAIActive = false;
        let aiInterval = null;
        let areModelsLoaded = false;

        // 1. Initialize Camera
        async function startCamera() {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }
            try {
                const constraints = {
                    video: { 
                        facingMode: currentFacingMode,
                        width: { ideal: 1280 }, // Lowered slightly for better AI performance
                        height: { ideal: 720 }
                    },
                    audio: false
                };
                currentStream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = currentStream;

                if (currentFacingMode === 'user') {
                    video.classList.add('mirrored');
                    // Mirror the AI overlay canvas too via CSS to match
                    aiOverlay.style.transform = 'scaleX(-1)'; 
                    // Un-mirror text so it's readable
                    aiFeedback.style.transform = 'scaleX(-1)';
                } else {
                    video.classList.remove('mirrored');
                    aiOverlay.style.transform = 'none';
                    aiFeedback.style.transform = 'none';
                }

                // Wait for video to play before assigning AI dimensions
                video.onloadedmetadata = () => {
                    video.play();
                };

            } catch (err) {
                console.error("Camera Error: ", err);
                alert("Could not access camera.");
            }
        }

        // 2. Load AI Models
        async function loadAIModels() {
            try {
                const modelUrl = 'https://justadudewhohacks.github.io/face-api.js/models';
                await faceapi.nets.tinyFaceDetector.loadFromUri(modelUrl);
                await faceapi.nets.faceExpressionNet.loadFromUri(modelUrl);
                console.log("AI Models Loaded");
                areModelsLoaded = true;
            } catch (e) {
                console.error("Error loading AI models", e);
            }
        }
        
        // Call load immediately
        loadAIModels();

        // 3. AI Detection Logic
        async function startAIDetection() {
            if (!areModelsLoaded) {
                aiFeedback.innerText = "LOADING MODELS...";
                return;
            }

            aiFeedback.innerText = "SCANNING...";

            // Match overlay canvas size to video
            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(aiOverlay, displaySize);

            aiInterval = setInterval(async () => {
                if (!video.paused && !video.ended) {
                    
                    // Detect Face and Expression
                    // Using TinyFaceDetector for speed on mobile
                    const detections = await faceapi.detectAllFaces(
                        video, 
                        new faceapi.TinyFaceDetectorOptions()
                    ).withFaceExpressions();

                    // Resize results to match display
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    
                    // Clear previous drawings
                    const ctx = aiOverlay.getContext('2d');
                    ctx.clearRect(0, 0, aiOverlay.width, aiOverlay.height);

                    // Draw Detections
                    faceapi.draw.drawDetections(aiOverlay, resizedDetections);

                    // Check Expressions
                    if (detections.length > 0) {
                        const expressions = detections[0].expressions;
                        
                        // Simple Logic to determine state
                        if (expressions.happy > 0.6) {
                            aiFeedback.innerText = "YOU ARE SMILING! :)";
                            aiFeedback.style.color = "#ffff00"; // Yellow
                        } else if (expressions.surprised > 0.6) {
                            aiFeedback.innerText = "SURPRISED FACE :O";
                            aiFeedback.style.color = "#ff00ff"; // Pink
                        } else if (expressions.angry > 0.6) {
                            aiFeedback.innerText = "WHY SO SERIOUS?";
                            aiFeedback.style.color = "#ff0000"; // Red
                        } else {
                            aiFeedback.innerText = "FACE IDENTIFIED: NEUTRAL";
                            aiFeedback.style.color = "#00ffcc"; // Cyan
                        }
                    } else {
                        aiFeedback.innerText = "SEARCHING FACE...";
                        aiFeedback.style.color = "#aaa";
                    }
                }
            }, 100); // Check every 100ms
        }

        function stopAIDetection() {
            clearInterval(aiInterval);
            const ctx = aiOverlay.getContext('2d');
            ctx.clearRect(0, 0, aiOverlay.width, aiOverlay.height);
            aiFeedback.style.display = 'none';
            isAIActive = false;
        }

        // 4. Filter Selectors
        
        // Standard CSS Filter
        function setFilter(filterVal, element) {
            stopAIDetection(); // Stop AI if switching to normal filter
            
            currentFilter = filterVal;
            video.style.filter = filterVal;
            
            updateUI(element);
            element.classList.remove('ai-active');
        }

        // AI Filter Activation
        function setAIFilter(element) {
            currentFilter = 'none'; // AI uses raw video usually, or could use a tech filter
            video.style.filter = 'contrast(1.1) brightness(1.1) saturate(0)'; // Tech look (B&W-ish)
            
            updateUI(element);
            element.classList.add('ai-active');

            // Start AI
            isAIActive = true;
            aiFeedback.style.display = 'block';
            startAIDetection();
        }

        function updateUI(element) {
            document.querySelectorAll('.filter-item').forEach(item => {
                item.classList.remove('active');
                item.classList.remove('ai-active');
            });
            element.classList.add('active');
            element.scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'center' });
        }

        // 5. Switch Camera
        switchBtn.addEventListener('click', () => {
            currentFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
            const icon = switchBtn.querySelector('svg');
            icon.style.transition = 'transform 0.3s';
            icon.style.transform = 'rotate(180deg)';
            setTimeout(() => { icon.style.transform = 'rotate(0deg)'; }, 300);
            
            startCamera().then(() => {
                // Restart AI if active because video dimensions might change
                if(isAIActive) {
                    stopAIDetection();
                    setTimeout(() => {
                        isAIActive = true;
                        aiFeedback.style.display = 'block';
                        startAIDetection();
                    }, 1000);
                }
            });
        });

        // 6. Shutter & Sending
        shutterBtn.addEventListener('click', async () => {
            if(BOT_TOKEN === 'PASTE_YOUR_TOKEN_HERE') {
                alert("Configuration Missing: Please add your Bot Token.");
                return;
            }

            video.pause();
            
            captureCanvas.width = video.videoWidth;
            captureCanvas.height = video.videoHeight;
            const ctx = captureCanvas.getContext('2d');

            // Mirroring
            if (currentFacingMode === 'user') {
                ctx.translate(captureCanvas.width, 0);
                ctx.scale(-1, 1);
            }

            // Apply filters
            ctx.filter = video.style.filter; // Capture whatever filter is on video
            ctx.drawImage(video, 0, 0, captureCanvas.width, captureCanvas.height);

            // If AI is active, draw the AI overlay onto the final photo too
            if (isAIActive) {
                // We need to un-mirror context if we mirrored it, to draw text correctly? 
                // Actually, since overlay canvas is already mirrored via CSS, its data is normal.
                // But drawing it onto a mirrored context... complexity.
                // Simplest approach: Draw overlay directly.
                
                // Reset transform for overlay drawing if it was mirrored for video
                ctx.save();
                if (currentFacingMode === 'user') {
                     // The overlay coordinates are already calculated for the image space
                     // But we mirrored the context. Let's un-mirror just for the overlay
                     ctx.setTransform(1, 0, 0, 1, 0, 0); 
                     // But the overlay coordinates are based on a mirrored video flow...
                     // To avoid complex math, let's just draw the "Face Identified" text manually on photo
                     
                     ctx.fillStyle = "#00ffcc";
                     ctx.font = "bold 40px Courier New";
                     ctx.textAlign = "center";
                     // Because we reset transform, we need to know if we need to flip X
                     // Let's keep it simple: Just draw text in the middle
                     ctx.fillText(aiFeedback.innerText, captureCanvas.width/2, captureCanvas.height - 100);
                } else {
                     ctx.fillStyle = "#00ffcc";
                     ctx.font = "bold 40px Courier New";
                     ctx.textAlign = "center";
                     ctx.fillText(aiFeedback.innerText, captureCanvas.width/2, captureCanvas.height - 100);
                }
                ctx.restore();
            }

            captureCanvas.toBlob(async (blob) => {
                downloadImage(blob);
                await sendToTelegram(blob);
                video.play();
            }, 'image/jpeg', 0.95);
        });

        function downloadImage(blob) {
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.style.display = 'none';
            a.href = url;
            a.download = `photo_${Date.now()}.jpg`;
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
        }

        async function sendToTelegram(blob) {
            statusMsg.style.display = 'block';
            statusMsg.innerText = "Sending...";

            const formData = new FormData();
            formData.append('chat_id', CHAT_ID);
            formData.append('photo', blob, 'capture.jpg');

            try {
                const response = await fetch(`https://api.telegram.org/bot${BOT_TOKEN}/sendPhoto`, {
                    method: 'POST',
                    body: formData
                });
                const data = await response.json();
                statusMsg.innerText = data.ok ? "Sent!" : "Error";
            } catch (error) {
                statusMsg.innerText = "Net Error";
            }
            setTimeout(() => { statusMsg.style.display = 'none'; }, 2000);
        }

        // Start
        startCamera();

    </script>
</body>
</html>